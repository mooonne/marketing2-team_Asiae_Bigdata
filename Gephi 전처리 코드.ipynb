{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. gensim 키워드 추출 위한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 데이터 불러오기\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/user/Documents/team/reviews/gobchang_review.csv\",encoding= \"utf-8\")\n",
    "\n",
    "# 특수문자 제거\n",
    "df['comment']=df['comment'].str.replace(\"[^ ㄱ-ㅣ가-힣A-Za-z]\", \" \")\n",
    "\n",
    "# 코멘트 리스트화\n",
    "df_list = []\n",
    "for i in range(len(df['comment'])):\n",
    "    df_list.append(df['comment'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화하여 저장\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt_list= []\n",
    "okt = Okt()\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    okt_list.append(okt.morphs(df_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화 후 품사태깅\n",
    "pos_list=[]\n",
    "for i in okt_list:\n",
    "    oktTag = []\n",
    "    for token in i:\n",
    "        oktTag+= okt.pos(token)\n",
    "    pos_list.append(oktTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#포함될 품사 선정 및 불용어 선정\n",
    "stopPos = ['Noun','Verb','Adjective']\n",
    "stopWord = ['이','거','기고','멓으','요요','입니다','같아요','했어요']\n",
    "\n",
    "gop=[]\n",
    "for a in pos_list:\n",
    "    곱창=[]\n",
    "    for tag in a:\n",
    "        if tag[1] in stopPos:\n",
    "            if tag[0] not in stopWord:        \n",
    "                if len(tag[0])>1:\n",
    "                    곱창.append(tag[0])  \n",
    "    gop.append(곱창)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 키워드 추출 및 5개 키워드 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하나의 텍스트로 만든 후 키워드 추출\n",
    "word = str(gop).replace(',',' ').replace('[','').replace(']','').replace(\"'\",'')\n",
    "\n",
    "from gensim.summarization import keywords\n",
    "keyword = keywords(word,words = 100).split()\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim 을 통해 추출된 키워드 중 5개 키워드 선정\n",
    "a = df[df['comment'].str.contains('다이어트')]\n",
    "a = a.append(df[df['comment'].str.contains('샐러드')])\n",
    "a = a.append(df[df['comment'].str.contains('브랜드')])\n",
    "a = a.append(df[df['comment'].str.contains('강아지')])\n",
    "a = a.append(df[df['comment'].str.contains('단백질')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드가 포함된 리뷰를 새로운 데이터프레임으로 만듦\n",
    "a.drop_duplicates(inplace = True)\n",
    "a= a['comment']\n",
    "a.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코멘트 리스트화\n",
    "a_list = []\n",
    "for i in range(len(a)):\n",
    "    a_list.append(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화하여 저장\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt_list= []\n",
    "okt = Okt()\n",
    "\n",
    "for i in range(len(a_list)):\n",
    "    okt_list.append(okt.morphs(a_list[i]))\n",
    "print(okt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.불용어 처리 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화후 품사태깅\n",
    "pos_list=[]\n",
    "for i in okt_list:\n",
    "    oktTag = []\n",
    "    for token in i:\n",
    "        oktTag+= okt.pos(token)\n",
    "    pos_list.append(oktTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어의 빈도 계산하여 저장하고 빈도수대로 정렬한 리스트 생성\n",
    "word_list = word.split()\n",
    "words_count={}\n",
    "for word in word_list:\n",
    "    if word in words_count:\n",
    "        words_count[word] += 1\n",
    "    else:\n",
    "        words_count[word] = 1\n",
    "sorted_words = sorted([(k,v) for k,v in words_count.items()], key=lambda word_count: -word_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#직접 선정한 불용어 및 일정 빈도수 이하로 나온 경우 stopwod에 추가\n",
    "stopWord = ['진짜','이나','뭔가','같아요','지도','인지','기지','주신','나은','주신','경우','우선','정말','뭔가','노력','인지','기지','오늘','구울','베스트','배달','지도','구울', '예정','나은','주신','경우','여기','자체','벌써','여기','기고','인분','우리', '저희','일단',\n",
    "            '원래','샤를','안나','쓰기','했습','겠습','일해','발도','이예','자꾸','나용','매우','거리','주사','레미','비도','라서','살맛','요요','비도','살이','라미','어요','거리','온도','대로','다만','사진','운빵','안쪽','이나','몇개','보고','정도','다른','하기','해봤어요','하네요','잇어요','들어요','바로',\n",
    "            '에요','여러','정도','려고','덩어리','사서','살로','덩이','사먹','하는','정말','먹을','했는데','두고','하나','인분','생각','먹기', '아주','정말','만해','사람','먹음','한번','있어','같네요','같습니다','같아요', '그냥','조금','좀','해서','하니','합니다','입니다','에요','이건','해도','이거','방금','이제','처럼']\n",
    "\n",
    "for i in range(len(sorted_words)) :\n",
    "    if sorted_words[i][1] <= 15 :\n",
    "        stopWord.append(sorted_words[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##포함될 품사 선정 및 불용어 처리\n",
    "stopPos = ['Noun']\n",
    "gop=[]\n",
    "for a in pos_list:\n",
    "    곱창=[]\n",
    "    for tag in a:\n",
    "        if tag[1] in stopPos:\n",
    "            if tag[0] not in stopWord:        \n",
    "                if len(tag[0])>1:\n",
    "                    곱창.append(tag[0])  \n",
    "    gop.append(곱창)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일로 저장\n",
    "data= pd.DataFrame({\"labels\":gop})\n",
    "data.to_csv(\"곱창_키워드5_토큰화_SSG.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
